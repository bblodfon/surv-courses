{
  "hash": "471dc07d57a80bcba49a1ffc63efa934",
  "result": {
    "markdown": "# Censoring and time-dependent treatment strategies {-}\n\n\n\n\n\n## Data {-}\n\nIn this practical we will use a simulated data set, which includes data on 1000 individuals. The data include information on time-dependent treatment status $A$, alongside three confounding variables ($X,L_1,L_2$), two of which are time-dependent. Individuals were followed up for death for up to 3 years.\n\nThe variables in the data are listed in the table below.\n\n- id => Individual identifier\n- visit => Visit number (0,1,2)\n- A => Treatment status, $A=0,1$, time-dependent\n- X => Time-fixed confounder, continuous\n- L1 => Time-dependent confounder, continuous\n- L2 => Time-dependent confounder, binary\n- T.start => Start time of follow-up period\n- T.stop => Stop time of follow-up period\n- D => Time-updated event indicator corresponding to T.stop\n\nYou can assume the relationships between the variables is as depicted in the discrete time DAG below, where $Y_t$ denotes the event indicator $D$ at time $t$ ($t=1,2,3$).\n\n![](img/dag1.png)\n\n## Aims {-}\n\nThis practical exercise is in two parts. \n\nIn **Part A** the aim is to estimate the effect of treatment status at time 0 ($A_0$) on survival up to 3 years. **This part ignores that treatment status changes over time**, and it can be considered as a type of intention-to-treat (ITT) analysis. In this part we will also explore how to handle dependent censoring using inverse probability of censoring weights (IPCW). \n\nIn **Part B** the aim is to **estimate the effect of sustained use of the treatment vs sustained non-use of the treatment** on survival up to 3 years. We will use the cloning-censoring-weighting approach to estimate the population average (marginal) survival curves if everyone had received treatment $A$ from time 0 onwards ($a_0=a_1=a_2=1$) and if everyone had not received treatment $A$ from time 0 onwards ($a_0=a_1=a_2=0$). \n\n## Load data and packages {-}\n\nIn this practical we will use the following packages: survival, tidyverse, splines.\n\n\n::: {.cell result='false' hash='time_dep_trts_cache/html/unnamed-chunk-1_fd2c1c7e997eab38a29ce186841c4a19'}\n\n```{.r .cell-code}\nlibrary(survival)\nlibrary(tidyverse)\nlibrary(splines)\n\ndta = readRDS(file = \"data/dta_long.rds\")\n```\n:::\n\n\n## Impact of baseline treatment status and using IPCW {-}\n\n1. Check out the format of the data. How many rows of data are there? How many events?\n\n\n::: {.cell hash='time_dep_trts_cache/html/unnamed-chunk-2_94dfb5341df8b55a2f8a87544a8c05b7'}\n\n```{.r .cell-code}\n#data for the first 5 individuals\ndta[dta$id%in%1:5,]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    id visit T.start    T.stop D A           X          L1 L2\n1.0  1     0       0 0.1158240 0 0 -0.06264538 -0.82276938  1\n2.0  2     0       0 1.0000000 0 0  0.01836433 -1.79637025  0\n2.1  2     1       1 2.0000000 0 0  0.01836433 -0.44665445  1\n2.2  2     2       2 2.6234834 0 1  0.01836433 -0.34086086  1\n3.0  3     0       0 1.0000000 0 1 -0.08356286  1.46577269  1\n3.1  3     1       1 2.0000000 0 1 -0.08356286  1.48940024  1\n3.2  3     2       2 3.0000000 0 0 -0.08356286 -1.13274309  0\n4.0  4     0       0 0.4539474 0 1  0.15952808  0.66796553  1\n5.0  5     0       0 0.4846428 0 0  0.03295078 -0.02254975  1\n```\n:::\n\n```{.r .cell-code}\ndim(dta)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1827    9\n```\n:::\n\n```{.r .cell-code}\ntable(dta$D)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   0    1 \n1640  187 \n```\n:::\n:::\n\n\n2. Generate the baseline values of $A,L_1,L_2$ (i.e. the values at time 0) so that the baseline values are stored in each row of data for a given individual. We will refer to these as $A_0, L_{10}, L_{20}$.\n\n\n::: {.cell hash='time_dep_trts_cache/html/unnamed-chunk-3_f81f1dca6dbba06ecf6fbaa3dc03fe21'}\n\n```{.r .cell-code}\ndta$A0 <- ave(dta$A, dta$id, FUN=function(x){x[1]})\ndta$L10 <- ave(dta$L1, dta$id, FUN=function(x){x[1]})\ndta$L20 <- ave(dta$L2, dta$id, FUN=function(x){x[1]})\n\nhead(dta)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    id visit T.start   T.stop D A           X         L1 L2 A0        L10 L20\n1.0  1     0       0 0.115824 0 0 -0.06264538 -0.8227694  1  0 -0.8227694   1\n2.0  2     0       0 1.000000 0 0  0.01836433 -1.7963702  0  0 -1.7963702   0\n2.1  2     1       1 2.000000 0 0  0.01836433 -0.4466544  1  0 -1.7963702   0\n2.2  2     2       2 2.623483 0 1  0.01836433 -0.3408609  1  0 -1.7963702   0\n3.0  3     0       0 1.000000 0 1 -0.08356286  1.4657727  1  1  1.4657727   1\n3.1  3     1       1 2.000000 0 1 -0.08356286  1.4894002  1  1  1.4657727   1\n```\n:::\n:::\n\n\n3. Perform an unweighted (i.e. unadjusted) Kaplan-Meier analysis by treatment status at baseline, $A_0$, and plot the estimated survival curves. Here we need to take account of the long format of the data using `Surv(T.start,T.stop,D)` in `survfit`. What is the crude association between $A_0$ and survival? Obtain the estimated survival probabilities at time 3. \n\n\n::: {.cell hash='time_dep_trts_cache/html/unnamed-chunk-4_899e6b9c5ebbae1967c517d93d0534bb'}\n\n```{.r .cell-code}\nkm.unwt<-survfit(Surv(T.start,T.stop,D)~A0,data=dta)\n\nplot(km.unwt, xlab=\"Time\",ylab=\"Survival probability\",\n     col=c(\"red\",\"blue\"),lwd=2,conf.int=F,main=\"\")\nlegend(x=\"bottomleft\",c(\"Treatment strategy A=0\",\"Treatment strategy A=1\"),\n       col=c(\"red\",\"blue\"),lty=1,lwd=2,bty=\"n\")\n```\n\n::: {.cell-output-display}\n![](time_dep_trts_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#survival probabilities at time 3\nsummary(km.unwt,times=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: survfit(formula = Surv(T.start, T.stop, D) ~ A0, data = dta)\n\n                A0=0 \n        time       n.risk      n.event     survival      std.err lower 95% CI \n      3.0000     112.0000     131.0000       0.6638       0.0268       0.6133 \nupper 95% CI \n      0.7184 \n\n                A0=1 \n        time       n.risk      n.event     survival      std.err lower 95% CI \n      3.0000      60.0000      56.0000       0.7153       0.0365       0.6472 \nupper 95% CI \n      0.7905 \n```\n:::\n:::\n\n\n3. In this question we will estimate marginal survival curves under the strategies of setting $A_0=1$ for everyone and setting $A_0=0$ for everyone, denoted $S^{a_0=1}(t)=\\mathbb{P}(T^{a_0=1}>t)$ and $S^{a_0=0}(t)=\\mathbb{P}(T^{a_0=0}>t)$.\n\na. Using a logistic regression model, generate inverse probability of treatment weights of the form\n$$\niptw=\\frac{A_0}{\\mathbb{P}(A_{0}=1|X,L_{10},L_{20})}+\\frac{(1-A_0)}{\\mathbb{P}(A_{0}=0|X,L_{10},L_{20})}\n$$\nThe model used to generate the weights should be fitted using only the first row of data for each individual.\nb. Perform a weighted Kaplan-Meier analysis by treatment status at baseline ($A_0$) using the weights generated in (a). \nc. Plot and interpret the estimated survival curves under the two treatment strategies. Obtain estimates of $S^{a_0=1}(t)$ and $S^{a_0=0}(t)$ for $t=3$.\n\n\n::: {.cell hash='time_dep_trts_cache/html/unnamed-chunk-5_93a7d03d37a4560bebbd7b63ec02ef34'}\n\n```{.r .cell-code}\n#Fit the model for treatment at baseline\nmod.treat<-glm(A0~X+L10+L20,\n               data=dta[dta$T.start==0,],family=\"binomial\")\n\n#predicted probability of treatment from the model for each individual\npred.treat<-predict(mod.treat,newdata=dta,type=\"response\")\n\n#Obtain the weight for each person\ndta$iptw<-(dta$A0==1)/pred.treat+(dta$A0==0)/(1-pred.treat)\n\n#Weighted Kaplan-Meier\nkm.wt<-survfit(Surv(T.start,T.stop,D)~A0,data=dta,weights = dta$iptw)\n\nplot(km.wt, xlab=\"Time\",ylab=\"Survival probability\",\n     col=c(\"red\",\"blue\"),lwd=2,conf.int=F,main=\"\")\nlegend(x=\"bottomleft\",c(\"Treatment strategy A0=0\",\"Treatment strategy A0=1\"),\n       col=c(\"red\",\"blue\"),lty=1,lwd=2,bty=\"n\")\n```\n\n::: {.cell-output-display}\n![](time_dep_trts_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#survival probabilities at time 3\nsummary(km.wt,times=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: survfit(formula = Surv(T.start, T.stop, D) ~ A0, data = dta, \n    weights = dta$iptw)\n\n                A0=0 \n        time       n.risk      n.event     censored     survival      std.err \n    3.00e+00     1.48e+02     2.50e+02     1.50e+03     5.93e-01     3.07e-02 \nlower 95% CI upper 95% CI \n    5.35e-01     6.56e-01 \n\n                A0=1 \n        time       n.risk      n.event     censored     survival      std.err \n    3.00e+00     2.63e+02     1.26e+02     1.92e+03     8.03e-01     3.42e-02 \nlower 95% CI upper 95% CI \n    7.38e-01     8.72e-01 \n```\n:::\n:::\n\n\n4. The analysis in question 3 assumes that any censoring in the data is independent of any variables that are also related to the outcome. It turns out that the censoring depends on $X$ and $L_2$, which are also related to the outcome (we know this because we generated the data!). In this question we will account for dependent censoring using inverse probability of censoring weights (IPCW) to estimate $S^{a_0=1,\\bar{c}_t=0}(t)=\\mathbb{P}(T^{a_0=1,\\bar{c}_t=0}>t)$ and $S^{a_0=0,\\bar{c}_t=0}(t)=\\mathbb{P}(T^{a_0=0,\\bar{c}_t=0}>t)$. \n\na. Generate an indicator for non-administrative censoring in each row for each individual. This should indicate whether the individual is (non-administratively) censored at time `T.stop`.\nb. Fit a logistic regression model with your censoring indicator as the outcome and with $A, X,L_1,L_2$ as covariates. Include visit as a factor variable. \nc. Use the model in (b) to estimate the inverse probability of censoring weight in each row:\n$$\nipcw(t)=\\prod_{k=1}^{t}\\frac{1}{\\mathbb{P}(C_k=0|\\bar C_{k-1}=0,\\bar{A}_k,X,\\bar{L}_{1k},\\bar{L}_{2k})}, \\quad t=1,2,3\n$$\nd. Generate a combined weight by multiplying the IPTW by the IPCW, and perform a weighted Kaplan-Meier analysis by treatment status at baseline ($A_0$). \ne. Plot and interpret the estimated survival curves under the two treatment strategies. Obtain estimates of $S^{a_0=1,\\bar{c}_t=0}(t)$ and $S^{a_0=1,\\bar{c}_t=0}(t)$ for $t=3$.\n\n\n::: {.cell hash='time_dep_trts_cache/html/unnamed-chunk-6_bd2b6db7900b03d69c4b6c484b649c85'}\n\n```{.r .cell-code}\n# Create event variable for censoring\ndta$censored <- ave(dta$D, dta$id, FUN = function(x){\n  ifelse(cumsum(x)==rep(0, length(x)), c(rep(0, length(x)-1), 1), rep(0, length(x)))})\ndta$censored <-ifelse(dta$T.stop==3 & dta$D==0,0,dta$censored) \n\n# Fit pooled logistic regressions with censoring as outcome:\ncwfit.denum <- glm(censored ~ as.factor(T.start) + A + X + L1 + L2, \n                   family=binomial, data=dta)\n\n# Predict individual censoring probabilities over time:\ncprob.denum <- predict(cwfit.denum, dta, type=\"response\")\n\n# Calculate IPCW's:\ndta$ipcw <- 1/(1-cprob.denum)\ndta$ipcw <- ave(dta$ipcw, dta$id, FUN = cumprod)\n\n#combined weights\ndta$comb.wt<-pmin(dta$ipcw*dta$iptw,50)\ndta$comb.wt<-pmin(dta$ipcw*dta$iptw,50)\n\n#Weighted Kaplan-Meier\nkm.wt2<-survfit(Surv(T.start,T.stop,D)~A0,data=dta,weights = dta$comb.wt)\n\nplot(km.wt2, xlab=\"Time\",ylab=\"Survival probability\",\n     col=c(\"red\",\"blue\"),lwd=2,conf.int=F,main=\"\")\nlegend(x=\"bottomleft\",c(\"Treatment strategy A0=0\",\"Treatment strategy A0=1\"),\n       col=c(\"red\",\"blue\"),lty=1,lwd=2,bty=\"n\")\n```\n\n::: {.cell-output-display}\n![](time_dep_trts_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#survival probabilities at time 3\nsummary(km.wt2,times=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: survfit(formula = Surv(T.start, T.stop, D) ~ A0, data = dta, \n    weights = dta$comb.wt)\n\n                A0=0 \n        time       n.risk      n.event     censored     survival      std.err \n    3.00e+00     4.82e+02     6.31e+02     3.57e+03     5.13e-01     4.39e-02 \nlower 95% CI upper 95% CI \n    4.34e-01     6.07e-01 \n\n                A0=1 \n        time       n.risk      n.event     censored     survival      std.err \n    3.00e+00     5.66e+02     3.39e+02     4.35e+03     7.38e-01     4.55e-02 \nlower 95% CI upper 95% CI \n    6.54e-01     8.32e-01 \n```\n:::\n:::\n\n\n5. EXTRA. The analysis in question 4 assumes that censoring only occurs at time 1, 2, or 3. The censoring times can actually be at any time (in this data set). One approach to allowing for this is to extend the analysis in 4 to allow censoring times to occur on a small grid of times, say $0.1,0.2,\\ldots,2.9,3.0$. To allow this the first step is to divide each individual's follow-up into smaller time periods according to the grid $0.1,0.2,\\ldots,2.9,3.0$, which can be done using the `survSplit` function:\n`dta.split<-survSplit(Surv(T.start,T.stop,D)~.,data=dta,cut=seq(0,3,0.1))`. \nThe rest of the analysis then follows as above, except that in the censoring weights model we recommend including a spline term for `T.start` instead of the separate indicator for each time (e.g. `ns(T.start,df=4)`). \n\n::: {.cell hash='time_dep_trts_cache/html/unnamed-chunk-7_c67cd728b3323d420d2ac7c6b047275a'}\n\n```{.r .cell-code}\ndta.split<-survSplit(Surv(T.start,T.stop,D)~.,data=dta,cut=seq(0,3,0.1))\n\n# Create new event variable for censoring\ndta.split$censored <- ave(dta.split$D, dta.split$id, FUN = function(x){\n  ifelse(cumsum(x)==rep(0, length(x)), c(rep(0, length(x)-1), 1), rep(0, length(x)))})\ndta.split$censored <-ifelse(dta.split$T.stop==3 & dta.split$D==0,0,dta.split$censored) \n\n# Fit pooled logistic regressions with censoring as outcome\ncwfit.denum <- glm(censored ~ ns(T.start,df=4) + A + X + L1 + L2, \n                   family=binomial, data=dta.split)\n\n# Predict individual censoring probabilities over time:\ncprob.denum <- predict(cwfit.denum, dta.split, type=\"response\")\n\n# Calculate IPCW's\ndta.split$ipcw <- 1/(1-cprob.denum)\ndta.split$ipcw <- ave(dta.split$ipcw, dta.split$id, FUN = cumprod)\n\n#combined weights\ndta.split$comb.wt<-dta.split$ipcw*dta.split$iptw\n\n#Weighted Kaplan-Meier\nkm.wt3<-survfit(Surv(T.start,T.stop,D)~A0,data=dta.split,weights = dta.split$comb.wt)\n\nplot(km.wt3, xlab=\"Time\",ylab=\"Survival probability\",\n     col=c(\"red\",\"blue\"),lwd=2,conf.int=F,main=\"\")\nlegend(x=\"bottomleft\",c(\"Treatment strategy A0=0\",\"Treatment strategy A0=1\"),\n       col=c(\"red\",\"blue\"),lty=1,lwd=2,bty=\"n\")\n```\n\n::: {.cell-output-display}\n![](time_dep_trts_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#survival probabilities at time 3\nsummary(km.wt3,times=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: survfit(formula = Surv(T.start, T.stop, D) ~ A0, data = dta.split, \n    weights = dta.split$comb.wt)\n\n                A0=0 \n        time       n.risk      n.event     censored     survival      std.err \n    3.00e+00     6.25e+02     5.55e+02     2.30e+04     4.82e-01     5.80e-02 \nlower 95% CI upper 95% CI \n    3.80e-01     6.10e-01 \n\n                A0=1 \n        time       n.risk      n.event     censored     survival      std.err \n    3.00e+00     6.40e+02     2.83e+02     2.75e+04     7.27e-01     4.90e-02 \nlower 95% CI upper 95% CI \n    6.37e-01     8.30e-01 \n```\n:::\n:::\n\n\n## Sustained treatment strategies and the cloning-censoring-weighting approach {-}\n\nThe aim in this part is to estimate survival curves if everyone had received treatment $A$ from time 0 onwards ($a_0=a_1=a_2=1$) and if everyone had not received treatment $A$ from time 0 onwards ($a_0=a_1=a_2=0$). The estimands are denoted $S^{\\underline{a}_0=1}(t)=\\mathbb{P}(T^{\\underline{a}_0=1}>t)$ and $S^{\\underline{a}_0=0}(t)=\\mathbb{P}(T^{\\underline{a}_0=0}>t)$. The questions below take us through the steps required to perform the cloning-censoring-weighting analysis.\n\n1. In this first question we will perform the *cloning* step and generate some variables needed for subsequent data manipulation and analysis.\n\na. Create two copies of the data, one corresponding to each of the two treatment strategies of interest. Denote these `clone.1` (for strategy $a_0=a_1=a_2=1$) and `clone.0` (for strategy $a_0=a_1=a_2=0$).\nb. In the `clone.1` data generate a new variable indicating whether a person has deviated from the strategy $a_0=a_1=a_2=1$. Note that some individuals deviate from this strategy immediately because they have $A_0=0$ in their first row. Keep all rows of data up to and including the *deviation row* in which the person first deviates from the strategy $a_0=a_1=a_2=1$, and discard rows after that in which the person has first deviated. Later we will drop the *deviation row*, but we need to keep it for now in order to estimate the artificial censoring weights (question 2!). \nc. Repeat (b) for the `clone.0` data, thinking now of the strategy $a_0=a_1=a_2=0$.\n\n\n::: {.cell hash='time_dep_trts_cache/html/unnamed-chunk-8_5c9323b4c11d665d03b70f6c9dd10bb4'}\n\n```{.r .cell-code}\n#Create two copies of the data\nclone.1<-dta\nclone.0<-dta\n\n#---\n#For clone.1\n\n#cumulative sum of treatment status being A=1\nclone.1$cumsumA<-ave(clone.1$A==1,clone.1$id,FUN=cumsum)\n\n#indicator of whether the person has deviated from A=1\nclone.1$switchA<-ifelse(clone.1$cumsumA==clone.1$T.start+1,0,1)\n\n#cumulative indicator of whether the person has deviated from A=1\nclone.1$switchA<-ave(clone.1$switchA,clone.1$id,FUN=cumsum)\n\n#drop if switchA>1 \n#because we are only going to use the rows where switchA=0 or 1 to estimate the weights.\nclone.1<-clone.1[clone.1$switchA<=1,]\n\n#---\n#For clone.0\n\n#cumulative sum of treatment status being A=0\nclone.0$cumsumA<-ave(clone.0$A==0,clone.0$id,FUN=cumsum)\n\n#indicator of whether the person has deviated from A=0\nclone.0$switchA<-ifelse(clone.0$cumsumA==clone.0$T.start+1,0,1)\n\n#cumulative indicator of whether the person has deviated from A=0\nclone.0$switchA<-ave(clone.0$switchA,clone.0$id,FUN=cumsum)\n\n#drop if cumsum.switchA>1 \n#because we are only going to use the rows where switchA=0 or 1 to estimate the weights.\nclone.0<-clone.0[clone.0$switchA<=1,]\n```\n:::\n\n\n2. In question 1 we have generated a variable `switchA` which is `switchA=0` in rows in which the individual is following the treatment strategy of interest, and which is `switchA=1` in the first row in which the person has deviated from the strategy (rows after this have been excluded). Next we will use this variable to estimate the *artificial censoring weights*. Consider first the data set `clone.1` and use the following steps:\n\na. Fit a logistic regression model with `switchA` as the outcome and with covariates the variables $X,L_{2},L_{1}$ from the same row, plus an indicator for `T.start`. This model can be fitted using all rows combined.\nb. Drop the rows in which `switchA=1`. we are now finished with this variable.\nc. Use the model in (a) to obtain the artificial censoring weights. The weight in a given row is the probability that a person remains uncensored (i.e. that they have not switched from the treatment strategy of interest):\n$$\nW(t)=\\prod_{k=0}^{t}\\frac{1}{\\mathbb{P}(switchA_k=0|X,L_{2k},L_{1k})},\\quad t=0,1,2\n$$\nd. Repeat steps (a)-(c) for the data set `clone.0`.\n\n\n::: {.cell hash='time_dep_trts_cache/html/unnamed-chunk-9_125fdd3a63ba267d0d777cdb9ed2c69f'}\n\n```{.r .cell-code}\n#weights models\n\nwt.mod.denom.1=glm(switchA~as.factor(T.start)+X+L1+L2,family=\"binomial\",data=clone.1)\nclone.1$wt.denom<-1-predict(wt.mod.denom.1,type = \"response\",newdata = clone.1)\n\nwt.mod.denom.0=glm(switchA~as.factor(T.start)+X+L1+L2,family=\"binomial\",data=clone.0)\nclone.0$wt.denom<-1-predict(wt.mod.denom.0,type = \"response\",newdata = clone.0)\n\n#drop the row where the switch occurred\n\nclone.1<-clone.1[clone.1$switchA==0,]\nclone.0<-clone.0[clone.0$switchA==0,]\n\n#ipcw for the artificial censoring\n\nclone.1$wt<-1/clone.1$wt.denom\nclone.1$wt<-ave(clone.1$wt,clone.1$id,FUN=cumprod)\n\nclone.0$wt<-1/clone.0$wt.denom\nclone.0$wt<-ave(clone.0$wt,clone.0$id,FUN=cumprod)\n```\n:::\n\n\n3. Finally, we perform the *weighting* step of the cloning-censoring-weighting approach, by performing a weighted analysis using the weights generated in question 2.\n\na. Using the data set `clone.1` perform a weighted Kaplan-Meier analysis to estimate $$S^{\\underline{a}_0=1}(t)=\\mathbb{P}(T^{\\underline{a}_0=1}>t)$$\nb. Using the data set `clone.0` perform a weighted Kaplan-Meier analysis to estimate $$S^{\\underline{a}_0=0}(t)=\\mathbb{P}(T^{\\underline{a}_0=0}>t)$$\nc. Compare the estimated survival curves in a plot and interpret the results. \nd. Obtain the estimated survival probability at time 3 under each treatment strategy, and the corresponding risk difference\n\n\n::: {.cell hash='time_dep_trts_cache/html/unnamed-chunk-10_abb2458a9bb4133dc4cf874fc6e0798d'}\n\n```{.r .cell-code}\nkm.1<-survfit(Surv(T.start,T.stop,D)~1,data=clone.1,weights = clone.1$wt)\nkm.0<-survfit(Surv(T.start,T.stop,D)~1,data=clone.0,weights = clone.0$wt)\n\nplot(km.1$time,km.1$surv,type=\"s\",col=\"blue\",lwd=2,\n     xlab=\"Time\",ylab=\"Survival probability\",ylim=c(0,1))\nlines(km.0$time,km.0$surv,type=\"s\",col=\"red\",lwd=2)\nlegend(\"bottomleft\",c(\"Sustained A=1\",\"Sustained A=0\"),col=c(\"blue\",\"red\"),lwd=2)\n```\n\n::: {.cell-output-display}\n![](time_dep_trts_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#survival probabilities and risk difference at time 3\nsummary(km.1,times=3)$surv\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8078718\n```\n:::\n\n```{.r .cell-code}\nsummary(km.0,times=3)$surv\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4359687\n```\n:::\n\n```{.r .cell-code}\n(1-summary(km.1,times=3)$surv)-(1-summary(km.0,times=3)$surv)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.3719031\n```\n:::\n:::\n\n\n4. EXTRA. The above cloning-censoring-weighting analysis does not account for any standard censoring that may depend on covariates. This can be done by combining the censoring weights estimated in Part A, with the cloning-censoring-weighting approach performed in Part B. We recommend estimating the standard censoring weights first.\n\n\n::: {.cell hash='time_dep_trts_cache/html/unnamed-chunk-11_f85786685420c989eef741b37aa86762'}\n\n```{.r .cell-code}\n#Demonstrated here by starting from dta.split, \n# which contains the ipcw for standard censoring.\n\n#Create two copies of the data\nclone.1<-dta.split\nclone.0<-dta.split\n\n#---\n#For clone.1\n\n#cumulative sum of treatment status being A=1\nclone.1$cumsumA<-ave(clone.1$A==1,clone.1$id,FUN=cumsum)\n\n#indicator of whether the person has deviated from A=1\nclone.1$rownum=ave(rep(1,dim(clone.1)[1]),clone.1$id,FUN=cumsum)\nclone.1$switchA<-ifelse(clone.1$cumsumA==clone.1$rownum,0,1)\n\n#cumulative indicator of whether the person has deviated from A=1\nclone.1$switchA<-ave(clone.1$switchA,clone.1$id,FUN=cumsum)\n\n#drop if switchA>1 \n#because we are only going to use the rows where switchA=0 or 1 to estimate the weights.\nclone.1<-clone.1[clone.1$switchA<=1,]\n\n#---\n#For clone.0\n\n#cumulative sum of treatment status being A=0\nclone.0$cumsumA<-ave(clone.0$A==0,clone.0$id,FUN=cumsum)\n\n#indicator of whether the person has deviated from A=0\nclone.0$rownum=ave(rep(1,dim(clone.0)[1]),clone.0$id,FUN=cumsum)\nclone.0$switchA<-ifelse(clone.0$cumsumA==clone.0$rownum,0,1)\n\n#cumulative indicator of whether the person has deviated from A=0\nclone.0$switchA<-ave(clone.0$switchA,clone.0$id,FUN=cumsum)\n\n#drop if cumsum.switchA>1 \n#because we are only going to use the rows where switchA=0 or 1 to estimate the weights.\nclone.0<-clone.0[clone.0$switchA<=1,]\n\n#weights models\n\nwt.mod.denom.1=glm(switchA~as.factor(visit)+X+L1+L2,family=\"binomial\",\n                   data=clone.1[clone.1$T.start%in%c(0,1,2),])\nclone.1$wt.denom<-1-predict(wt.mod.denom.1,type = \"response\",newdata = clone.1)\n\nwt.mod.denom.0=glm(switchA~as.factor(visit)+X+L1+L2,family=\"binomial\",\n                   data=clone.0[clone.0$T.start%in%c(0,1,2),])\nclone.0$wt.denom<-1-predict(wt.mod.denom.0,type = \"response\",newdata = clone.0)\n\n#drop the row where the switch occurred\n\nclone.1<-clone.1[clone.1$switchA==0,]\nclone.0<-clone.0[clone.0$switchA==0,]\n\n#ipcw for the artificial censoring\n\nclone.1$wt<-ifelse(clone.1$T.start%in%c(0,1,2),1/clone.1$wt.denom,1)\nclone.1$wt<-ave(clone.1$wt,clone.1$id,FUN=cumprod)\n\nclone.0$wt<-ifelse(clone.0$T.start%in%c(0,1,2),1/clone.0$wt.denom,1)\nclone.0$wt<-ave(clone.0$wt,clone.0$id,FUN=cumprod)\n\n#combine the artificial censoring weight with the standard censoring weight\nclone.1$comb.wt<-clone.1$wt*clone.1$ipcw\nclone.0$comb.wt<-clone.0$wt*clone.0$ipcw\n\n#weighted Kaplan-Meier analyses\n#Note that if we use wt instead of comb.wt then the results are \n# identical to those in question 4, as they should be\nkm.1<-survfit(Surv(T.start,T.stop,D)~1,data=clone.1,weights = clone.1$comb.wt)\nkm.0<-survfit(Surv(T.start,T.stop,D)~1,data=clone.0,weights = clone.0$comb.wt)\n\nplot(km.1$time,km.1$surv,type=\"s\",col=\"blue\",lwd=2,\n     xlab=\"Time\",ylab=\"Survival probability\",ylim=c(0,1))\nlines(km.0$time,km.0$surv,type=\"s\",col=\"red\",lwd=2)\nlegend(\"bottomleft\",c(\"Sustained A=1\",\"Sustained A=0\"),col=c(\"blue\",\"red\"),lwd=2)\n```\n\n::: {.cell-output-display}\n![](time_dep_trts_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#survival probabilities and risk difference at time 3\nsummary(km.1,times=3)$surv\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7254016\n```\n:::\n\n```{.r .cell-code}\nsummary(km.0,times=3)$surv\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2601855\n```\n:::\n\n```{.r .cell-code}\n(1-summary(km.1,times=3)$surv)-(1-summary(km.0,times=3)$surv)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.4652161\n```\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}